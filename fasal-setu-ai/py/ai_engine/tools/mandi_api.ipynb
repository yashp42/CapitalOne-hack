{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "80a54155",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO\n",
    "def prices_fetch(args):\n",
    "\t# Stub: Return fake mandi prices\n",
    "\treturn {\"data\": [{\"commodity\": \"wheat\", \"price\": 2000}], \"source_stamp\": \"mandi_stub\"}\n",
    "# TODO\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3cec4bc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# If needed — safe to re-run\n",
    "%pip install --quiet requests pydantic langchain langchain-core python-dateutil pandas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "99d75310",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import math\n",
    "import pathlib\n",
    "from datetime import datetime, date\n",
    "from typing import Any, Dict, List, Optional\n",
    "\n",
    "import requests\n",
    "from dateutil import parser as dateparser\n",
    "from pydantic import BaseModel, Field, validator\n",
    "\n",
    "# LangChain imports (works for LC >= 0.2.x)\n",
    "try:\n",
    "    from langchain_core.tools import StructuredTool\n",
    "except ImportError:\n",
    "    # fallback for older LC\n",
    "    from langchain.tools import StructuredTool\n",
    "\n",
    "# ---- Constants ----\n",
    "OGD_RESOURCE_ID = \"9ef84268-d588-465a-a308-a864a43d0070\"\n",
    "OGD_BASE = \"https://api.data.gov.in/resource/\"  # final endpoint = OGD_BASE + OGD_RESOURCE_ID\n",
    "DEFAULT_LIMIT = 500  # we’ll page if needed\n",
    "STATIC_DIR = pathlib.Path(\"static_json\")  # fallback folder\n",
    "MANDI_STATIC_GLOB = \"*.json\"             # e.g., agmarknet_*.json\n",
    "\n",
    "# ENV VAR for your data.gov.in API key\n",
    "OGD_API_KEY = os.getenv(\"DATA_GOV_IN_API_KEY\", \"\").strip()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "49e7bd4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "print(OGD_API_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "682758d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Hp\\AppData\\Local\\Temp\\ipykernel_19496\\2233489019.py:11: PydanticDeprecatedSince20: Pydantic V1 style `@validator` validators are deprecated. You should migrate to Pydantic V2 style `@field_validator` validators, see the migration guide for more details. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.11/migration/\n",
      "  @validator(\"start_date\", \"end_date\")\n"
     ]
    }
   ],
   "source": [
    "class MandiArgs(BaseModel):\n",
    "    state: str = Field(..., description=\"State name (e.g., 'Karnataka')\")\n",
    "    district: str = Field(..., description=\"District name (e.g., 'Belagavi')\")\n",
    "    commodity: str = Field(..., description=\"Commodity name (e.g., 'Tomato')\")\n",
    "    market: Optional[str] = Field(None, description=\"Market/APMC name\")\n",
    "    variety: Optional[str] = Field(None, description=\"Variety name\")\n",
    "    start_date: Optional[str] = Field(None, description=\"YYYY-MM-DD inclusive\")\n",
    "    end_date: Optional[str] = Field(None, description=\"YYYY-MM-DD inclusive\")\n",
    "    max_rows: int = Field(1000, description=\"Hard cap on rows to return after filtering\")\n",
    "\n",
    "    @validator(\"start_date\", \"end_date\")\n",
    "    def _date_fmt(cls, v):\n",
    "        if v is None: \n",
    "            return v\n",
    "        # accept several forms; normalize to YYYY-MM-DD\n",
    "        dt = dateparser.parse(v).date()\n",
    "        return dt.isoformat()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "844fd1ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _to_float(x):\n",
    "    if x is None: \n",
    "        return None\n",
    "    try:\n",
    "        return float(str(x).strip())\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "def _norm_str(x):\n",
    "    if x is None: \n",
    "        return None\n",
    "    s = str(x).strip()\n",
    "    return s if s else None\n",
    "\n",
    "def _in_date_range(d: str, start: Optional[str], end: Optional[str]) -> bool:\n",
    "    if not d:\n",
    "        return False\n",
    "    try:\n",
    "        dd = dateparser.parse(d).date()\n",
    "    except Exception:\n",
    "        return False\n",
    "    if start:\n",
    "        if dd < dateparser.parse(start).date():\n",
    "            return False\n",
    "    if end:\n",
    "        if dd > dateparser.parse(end).date():\n",
    "            return False\n",
    "    return True\n",
    "\n",
    "def _map_row_to_schema(r: Dict[str, Any], source_url: str) -> Dict[str, Any]:\n",
    "    # API fields commonly exposed by AGMARKNET via OGD: state, district, market, commodity, variety,\n",
    "    # modal_price, min_price, max_price, arrival_date, arrival, and sometimes unit, etc.\n",
    "    # We normalize into your target schema keys and types.\n",
    "    return {\n",
    "        \"state\": _norm_str(r.get(\"state\")) or _norm_str(r.get(\"State\")),\n",
    "        \"district\": _norm_str(r.get(\"district\")) or _norm_str(r.get(\"District\")),\n",
    "        \"market\": _norm_str(r.get(\"market\")) or _norm_str(r.get(\"Market\")),\n",
    "        \"arrival_date\": _norm_str(r.get(\"arrival_date\")) or _norm_str(r.get(\"date\")) or _norm_str(r.get(\"Date\")),\n",
    "        \"commodity\": _norm_str(r.get(\"commodity\")) or _norm_str(r.get(\"Commodity\")),\n",
    "        \"variety\": _norm_str(r.get(\"variety\")) or _norm_str(r.get(\"Variety\")),\n",
    "        \"min_price_rs_per_qtl\": _to_float(r.get(\"min_price\") or r.get(\"Min Price\")),\n",
    "        \"max_price_rs_per_qtl\": _to_float(r.get(\"max_price\") or r.get(\"Max Price\")),\n",
    "        \"modal_price_rs_per_qtl\": _to_float(r.get(\"modal_price\") or r.get(\"Modal Price\")),\n",
    "        \"arrival_qty\": _to_float(r.get(\"arrival\") or r.get(\"Arrivals\") or r.get(\"arrival_qty\")),\n",
    "        \"source_url\": source_url,\n",
    "        \"last_checked\": date.today().isoformat(),\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c3880404",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _fetch_from_ogd(args: MandiArgs) -> Dict[str, Any]:\n",
    "    if not OGD_API_KEY:\n",
    "        raise RuntimeError(\"DATA_GOV_IN_API_KEY not set in environment.\")\n",
    "\n",
    "    # Build base URL and params\n",
    "    url = f\"{OGD_BASE}{OGD_RESOURCE_ID}\"\n",
    "    params = {\n",
    "        \"api-key\": OGD_API_KEY,\n",
    "        \"format\": \"json\",\n",
    "        \"limit\": DEFAULT_LIMIT,\n",
    "        \"offset\": 0,\n",
    "        # NB: Official OGD supports `filters[field]=value` style filtering.\n",
    "        f\"filters[state]\": args.state,\n",
    "        f\"filters[district]\": args.district,\n",
    "        f\"filters[commodity]\": args.commodity,\n",
    "    }\n",
    "    if args.market:\n",
    "        params[\"filters[market]\"] = args.market\n",
    "    if args.variety:\n",
    "        params[\"filters[variety]\"] = args.variety\n",
    "\n",
    "    # We’ll page until we either reach max_rows or results run out.\n",
    "    rows: List[Dict[str, Any]] = []\n",
    "    total_fetched = 0\n",
    "    while True:\n",
    "        resp = requests.get(url, params=params, timeout=30)\n",
    "        resp.raise_for_status()\n",
    "        payload = resp.json()\n",
    "        batch = payload.get(\"records\") or payload.get(\"data\") or []\n",
    "        if not batch:\n",
    "            break\n",
    "\n",
    "        rows.extend(batch)\n",
    "        total_fetched += len(batch)\n",
    "        if total_fetched >= args.max_rows:\n",
    "            break\n",
    "\n",
    "        # next page\n",
    "        params[\"offset\"] = params.get(\"offset\", 0) + params[\"limit\"]\n",
    "\n",
    "        # simple stop if fewer than a full page returned\n",
    "        if len(batch) < params[\"limit\"]:\n",
    "            break\n",
    "\n",
    "    # Client-side date filter (API date filtering is inconsistent across resources)\n",
    "    filtered = []\n",
    "    for r in rows:\n",
    "        mapped = _map_row_to_schema(r, source_url=url)\n",
    "        if _in_date_range(mapped[\"arrival_date\"], args.start_date, args.end_date):\n",
    "            filtered.append(mapped)\n",
    "\n",
    "    return {\n",
    "        \"data\": filtered[: args.max_rows],\n",
    "        \"source_stamp\": url,\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c84069f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _fetch_from_static(args: MandiArgs) -> Dict[str, Any]:\n",
    "    if not STATIC_DIR.exists():\n",
    "        return {\"data\": [], \"source_stamp\": str(STATIC_DIR)}\n",
    "\n",
    "    all_rows: List[Dict[str, Any]] = []\n",
    "    for fp in STATIC_DIR.glob(MANDI_STATIC_GLOB):\n",
    "        try:\n",
    "            with open(fp, \"r\", encoding=\"utf-8\") as f:\n",
    "                raw = json.load(f)\n",
    "        except Exception:\n",
    "            continue\n",
    "\n",
    "        # raw can be: list of dicts OR {records: [...]} OR {data: [...]}\n",
    "        if isinstance(raw, dict):\n",
    "            candidates = raw.get(\"records\") or raw.get(\"data\") or raw.get(\"rows\") or []\n",
    "        elif isinstance(raw, list):\n",
    "            candidates = raw\n",
    "        else:\n",
    "            candidates = []\n",
    "\n",
    "        for r in candidates:\n",
    "            mapped = _map_row_to_schema(r, source_url=str(fp))\n",
    "            # basic filters\n",
    "            if mapped[\"state\"] and mapped[\"state\"].lower() != args.state.lower():\n",
    "                continue\n",
    "            if mapped[\"district\"] and mapped[\"district\"].lower() != args.district.lower():\n",
    "                continue\n",
    "            if mapped[\"commodity\"] and mapped[\"commodity\"].lower() != args.commodity.lower():\n",
    "                continue\n",
    "            if args.market and mapped[\"market\"] and mapped[\"market\"].lower() != args.market.lower():\n",
    "                continue\n",
    "            if args.variety and mapped[\"variety\"] and mapped[\"variety\"].lower() != args.variety.lower():\n",
    "                continue\n",
    "            if not _in_date_range(mapped[\"arrival_date\"], args.start_date, args.end_date):\n",
    "                continue\n",
    "            all_rows.append(mapped)\n",
    "\n",
    "    return {\n",
    "        \"data\": all_rows[: args.max_rows],\n",
    "        \"source_stamp\": str(STATIC_DIR.resolve()),\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "90b41dcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prices_fetch(args: Dict[str, Any]) -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Contract:\n",
    "      input: dict with keys: state, district, commodity, [market], [variety], [start_date], [end_date], [max_rows]\n",
    "      output: { \"data\": [ ...schema rows... ], \"source_stamp\": \"<API URL or file path>\" }\n",
    "    \"\"\"\n",
    "    parsed = MandiArgs(**args)\n",
    "\n",
    "    # Try OGD API first; if not available, fallback to static JSON.\n",
    "    try:\n",
    "        if OGD_API_KEY:\n",
    "            return _fetch_from_ogd(parsed)\n",
    "        else:\n",
    "            # No key, go static\n",
    "            return _fetch_from_static(parsed)\n",
    "    except Exception as e:\n",
    "        # Robust fallback\n",
    "        try:\n",
    "            return _fetch_from_static(parsed)\n",
    "        except Exception:\n",
    "            raise e\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c5fce58a",
   "metadata": {},
   "outputs": [],
   "source": [
    "MandiPricesTool = StructuredTool.from_function(\n",
    "    func=prices_fetch,\n",
    "    name=\"mandi_prices_lookup\",\n",
    "    description=(\n",
    "        \"Fetch daily mandi (wholesale) prices from AGMARKNET/OGD (or local static fallback). \"\n",
    "        \"Inputs: state, district, commodity, [market], [variety], [start_date], [end_date], [max_rows]. \"\n",
    "        \"Returns: {'data': [...], 'source_stamp': '...'} matching the Fasal-Setu mandi schema.\"\n",
    "    ),\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dcc3b1f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Mandi Tool Demo ===\n",
      "Args: {'state': 'Karnataka', 'district': 'Belagavi', 'commodity': 'Tomato', 'start_date': '2025-08-08', 'end_date': '2025-08-15', 'max_rows': 50}\n",
      "Source: static_json\n",
      "Rows: 0\n"
     ]
    }
   ],
   "source": [
    "# Example demo call — adjust district/commodity to something that exists in your sample/static files\n",
    "demo_args = {\n",
    "    \"state\": \"Karnataka\",\n",
    "    \"district\": \"Belagavi\",\n",
    "    \"commodity\": \"Tomato\",\n",
    "    \"start_date\": (date.today().replace(day=max(1, date.today().day-7))).isoformat(),\n",
    "    \"end_date\": date.today().isoformat(),\n",
    "    \"max_rows\": 50,\n",
    "}\n",
    "\n",
    "res = prices_fetch(demo_args)\n",
    "\n",
    "print(\"=== Mandi Tool Demo ===\")\n",
    "print(\"Args:\", demo_args)\n",
    "print(\"Source:\", res.get(\"source_stamp\"))\n",
    "print(\"Rows:\", len(res.get(\"data\", [])))\n",
    "for i, row in enumerate(res.get(\"data\", [])[:5], 1):\n",
    "    print(f\"\\n#{i} {row['arrival_date']} | {row['state']} > {row['district']} > {row.get('market')}\")\n",
    "    print(f\"   {row['commodity']} ({row.get('variety')})  modal={row['modal_price_rs_per_qtl']}  \"\n",
    "          f\"min={row['min_price_rs_per_qtl']}  max={row['max_price_rs_per_qtl']}  arrival={row.get('arrival_qty')}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a0b22bb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source: static_json\n",
      "Rows: 0\n",
      "First row: None\n"
     ]
    }
   ],
   "source": [
    "# Cell D2 — Live API smoke test (adjust args to a real combo that exists frequently)\n",
    "test_args = {\n",
    "    \"state\": \"Bihar\",\n",
    "    \"district\": \"Patna\",\n",
    "    \"commodity\": \"Tomato\",\n",
    "    \"start_date\": (date.today().replace(day=max(1, date.today().day-7))).isoformat(),\n",
    "    \"end_date\": date.today().isoformat(),\n",
    "    \"max_rows\": 50,\n",
    "}\n",
    "out = prices_fetch(test_args)\n",
    "print(\"Source:\", out[\"source_stamp\"])\n",
    "print(\"Rows:\", len(out[\"data\"]))\n",
    "print(\"First row:\", out[\"data\"][0] if out[\"data\"] else None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "3f6476c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, json, time\n",
    "from datetime import date\n",
    "from typing import Any, Dict, List, Optional\n",
    "\n",
    "import requests\n",
    "from pydantic import BaseModel, Field, validator\n",
    "from dateutil import parser as dateparser\n",
    "\n",
    "try:\n",
    "    from langchain_core.tools import StructuredTool\n",
    "except ImportError:\n",
    "    from langchain.tools import StructuredTool\n",
    "\n",
    "# === data.gov.in (AGMARKNET) ===\n",
    "OGD_RESOURCE_ID = \"9ef84268-d588-465a-a308-a864a43d0070\"  # Current Daily Price of Various Commodities...\n",
    "OGD_BASE = \"https://api.data.gov.in/resource/\"\n",
    "OGD_API_KEY = os.getenv(\"DATA_GOV_IN_API_KEY\", \"\").strip()\n",
    "\n",
    "DEFAULT_LIMIT = 500\n",
    "DEFAULT_SLEEP_BETWEEN_PAGES = 0.25  # be nice to API\n",
    "\n",
    "# Optional alias normalization (helps Belagavi/Belgaum etc.)\n",
    "ALIASES = {\n",
    "    \"district\": {\n",
    "        \"belgaum\": \"belagavi\",\n",
    "        \"bangalore rural\": \"bengaluru rural\",\n",
    "        \"bangalore\": \"bengaluru urban\",\n",
    "    },\n",
    "    \"market\": {\n",
    "        \"belgaum apmc\": \"belagavi apmc\",\n",
    "        \"belgaum\": \"belagavi\",\n",
    "    },\n",
    "    \"commodity\": {\n",
    "        \"tomatoes\": \"tomato\",\n",
    "    },\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "7d022b12",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _canon(val: Optional[str], kind: str) -> Optional[str]:\n",
    "    if not val: return val\n",
    "    key = val.strip().lower()\n",
    "    return ALIASES.get(kind, {}).get(key, val)\n",
    "\n",
    "def _norm_str(x):\n",
    "    if x is None: return None\n",
    "    s = str(x).strip()\n",
    "    return s if s else None\n",
    "\n",
    "def _to_float(x):\n",
    "    try:\n",
    "        return float(str(x).strip())\n",
    "    except Exception:\n",
    "        return None\n",
    "\n",
    "def _in_date_range(d: Optional[str], start: Optional[str], end: Optional[str]) -> bool:\n",
    "    if not d:\n",
    "        return False\n",
    "    dd = dateparser.parse(d).date()\n",
    "    if start and dd < dateparser.parse(start).date():\n",
    "        return False\n",
    "    if end and dd > dateparser.parse(end).date():\n",
    "        return False\n",
    "    return True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a6414dfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _ogd_call(params: Dict[str, Any]) -> Dict[str, Any]:\n",
    "    if not OGD_API_KEY:\n",
    "        raise RuntimeError(\"DATA_GOV_IN_API_KEY is not set. Get a key on data.gov.in and set it in env.\")\n",
    "    url = f\"{OGD_BASE}{OGD_RESOURCE_ID}\"\n",
    "    resp = requests.get(url, params=params, timeout=30)\n",
    "    resp.raise_for_status()\n",
    "    return resp.json()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ad1cf599",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Hp\\AppData\\Local\\Temp\\ipykernel_19496\\692113237.py:11: PydanticDeprecatedSince20: Pydantic V1 style `@validator` validators are deprecated. You should migrate to Pydantic V2 style `@field_validator` validators, see the migration guide for more details. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.11/migration/\n",
      "  @validator(\"start_date\", \"end_date\")\n"
     ]
    }
   ],
   "source": [
    "class AgmarknetQuery(BaseModel):\n",
    "    commodity: str = Field(..., description=\"Commodity, e.g., 'Tomato'\")\n",
    "    state: str = Field(..., description=\"State, e.g., 'Karnataka'\")\n",
    "    market: Optional[str] = Field(None, description=\"Market/APMC name\")\n",
    "    district: Optional[str] = Field(None, description=\"District name\")\n",
    "    variety: Optional[str] = Field(None, description=\"Variety name\")\n",
    "    start_date: Optional[str] = Field(None, description=\"YYYY-MM-DD\")\n",
    "    end_date: Optional[str] = Field(None, description=\"YYYY-MM-DD\")\n",
    "    max_rows: int = Field(1000, description=\"Cap returned rows\")\n",
    "\n",
    "    @validator(\"start_date\", \"end_date\")\n",
    "    def _datefmt(cls, v):\n",
    "        if v is None: return v\n",
    "        return dateparser.parse(v).date().isoformat()\n",
    "\n",
    "def agmarknet_request(\n",
    "    commodity: str,\n",
    "    state: str,\n",
    "    market: Optional[str] = None,\n",
    "    district: Optional[str] = None,\n",
    "    variety: Optional[str] = None,\n",
    "    start_date: Optional[str] = None,\n",
    "    end_date: Optional[str] = None,\n",
    "    max_rows: int = 1000,\n",
    ") -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Fetch raw AGMARKNET rows from data.gov.in for the given filters.\n",
    "    Mimics the GitHub repo interface (commodity/state/market) but uses the official API.\n",
    "    Returns: { \"records\": [...], \"source_url\": \"<API URL with resource id>\" }\n",
    "    \"\"\"\n",
    "    q = AgmarknetQuery(\n",
    "        commodity=commodity, state=state, market=market, district=district,\n",
    "        variety=variety, start_date=start_date, end_date=end_date, max_rows=max_rows\n",
    "    )\n",
    "\n",
    "    # Build filters (API uses filters[field]=value)\n",
    "    base_params = {\n",
    "        \"api-key\": OGD_API_KEY,\n",
    "        \"format\": \"json\",\n",
    "        \"limit\": DEFAULT_LIMIT,\n",
    "        \"offset\": 0,\n",
    "        \"filters[commodity]\": _canon(q.commodity, \"commodity\") or q.commodity,\n",
    "        \"filters[state]\": q.state,\n",
    "    }\n",
    "    if q.district:\n",
    "        base_params[\"filters[district]\"] = _canon(q.district, \"district\") or q.district\n",
    "    if q.market:\n",
    "        base_params[\"filters[market]\"] = _canon(q.market, \"market\") or q.market\n",
    "    if q.variety:\n",
    "        base_params[\"filters[variety]\"] = q.variety\n",
    "\n",
    "    all_rows: List[Dict[str, Any]] = []\n",
    "    url = f\"{OGD_BASE}{OGD_RESOURCE_ID}\"\n",
    "\n",
    "    while True:\n",
    "        payload = _ogd_call(base_params)\n",
    "        batch = payload.get(\"records\") or payload.get(\"data\") or []\n",
    "        if not batch:\n",
    "            break\n",
    "\n",
    "        # Client-side date filter (resource date filtering is inconsistent)\n",
    "        for r in batch:\n",
    "            # try common date keys from AGMARKNET feed\n",
    "            d = r.get(\"arrival_date\") or r.get(\"date\") or r.get(\"Date\")\n",
    "            if (q.start_date or q.end_date):\n",
    "                if not _in_date_range(d, q.start_date, q.end_date):\n",
    "                    continue\n",
    "            all_rows.append(r)\n",
    "            if len(all_rows) >= q.max_rows:\n",
    "                break\n",
    "\n",
    "        if len(all_rows) >= q.max_rows:\n",
    "            break\n",
    "\n",
    "        # pagination\n",
    "        prev = base_params[\"offset\"]\n",
    "        base_params[\"offset\"] = prev + base_params[\"limit\"]\n",
    "        if len(batch) < base_params[\"limit\"]:\n",
    "            break\n",
    "        time.sleep(DEFAULT_SLEEP_BETWEEN_PAGES)\n",
    "\n",
    "    return {\"records\": all_rows, \"source_url\": url}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d63da566",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _map_row_to_schema(r: Dict[str, Any], source_url: str) -> Dict[str, Any]:\n",
    "    state = _norm_str(r.get(\"state\") or r.get(\"State\"))\n",
    "    district = _norm_str(r.get(\"district\") or r.get(\"District\"))\n",
    "    market = _norm_str(r.get(\"market\") or r.get(\"Market\"))\n",
    "    commodity = _norm_str(r.get(\"commodity\") or r.get(\"Commodity\"))\n",
    "    variety = _norm_str(r.get(\"variety\") or r.get(\"Variety\"))\n",
    "    arrival_date = _norm_str(r.get(\"arrival_date\") or r.get(\"date\") or r.get(\"Date\"))\n",
    "\n",
    "    # alias normalization\n",
    "    district = _canon(district, \"district\") if district else district\n",
    "    market   = _canon(market, \"market\") if market else market\n",
    "    commodity= _canon(commodity, \"commodity\") if commodity else commodity\n",
    "\n",
    "    return {\n",
    "        \"state\": state,\n",
    "        \"district\": district,\n",
    "        \"market\": market,\n",
    "        \"arrival_date\": arrival_date,\n",
    "        \"commodity\": commodity,\n",
    "        \"variety\": variety,\n",
    "        \"min_price_rs_per_qtl\": _to_float(r.get(\"min_price\") or r.get(\"Min Price\")),\n",
    "        \"max_price_rs_per_qtl\": _to_float(r.get(\"max_price\") or r.get(\"Max Price\")),\n",
    "        \"modal_price_rs_per_qtl\": _to_float(r.get(\"modal_price\") or r.get(\"Modal Price\")),\n",
    "        \"arrival_qty\": _to_float(r.get(\"arrival\") or r.get(\"Arrivals\") or r.get(\"arrival_qty\")),\n",
    "        \"source_url\": source_url,\n",
    "        \"last_checked\": date.today().isoformat(),\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "5e172b06",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Hp\\AppData\\Local\\Temp\\ipykernel_19496\\585644801.py:11: PydanticDeprecatedSince20: Pydantic V1 style `@validator` validators are deprecated. You should migrate to Pydantic V2 style `@field_validator` validators, see the migration guide for more details. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.11/migration/\n",
      "  @validator(\"start_date\", \"end_date\")\n"
     ]
    }
   ],
   "source": [
    "class MandiArgs(BaseModel):\n",
    "    state: str\n",
    "    district: Optional[str] = None\n",
    "    commodity: str\n",
    "    market: Optional[str] = None\n",
    "    variety: Optional[str] = None\n",
    "    start_date: Optional[str] = None\n",
    "    end_date: Optional[str] = None\n",
    "    max_rows: int = 1000\n",
    "\n",
    "    @validator(\"start_date\", \"end_date\")\n",
    "    def _datefmt(cls, v):\n",
    "        if v is None: return v\n",
    "        return dateparser.parse(v).date().isoformat()\n",
    "\n",
    "def prices_fetch(args: Dict[str, Any]) -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Inputs: state, district, commodity, [market], [variety], [start_date], [end_date], [max_rows]\n",
    "    Returns:\n",
    "      {\n",
    "        \"data\": [ ...schema rows... ],\n",
    "        \"source_stamp\": \"<API URL>\"\n",
    "      }\n",
    "    \"\"\"\n",
    "    a = MandiArgs(**args)\n",
    "    raw = agmarknet_request(\n",
    "        commodity=a.commodity,\n",
    "        state=a.state,\n",
    "        market=a.market,\n",
    "        district=a.district,\n",
    "        variety=a.variety,\n",
    "        start_date=a.start_date,\n",
    "        end_date=a.end_date,\n",
    "        max_rows=a.max_rows,\n",
    "    )\n",
    "    data = [_map_row_to_schema(r, raw[\"source_url\"]) for r in raw[\"records\"]]\n",
    "    return {\"data\": data, \"source_stamp\": raw[\"source_url\"]}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "dd3f8454",
   "metadata": {},
   "outputs": [],
   "source": [
    "MandiPricesTool = StructuredTool.from_function(\n",
    "    func=prices_fetch,\n",
    "    name=\"mandi_prices_lookup\",\n",
    "    description=(\n",
    "        \"Fetch mandi prices from AGMARKNET via data.gov.in (API only). \"\n",
    "        \"Inputs: state, district, commodity, [market], [variety], [start_date], [end_date], [max_rows]. \"\n",
    "        \"Returns {data: [...], source_stamp: '...'} in Fasal-Setu schema.\"\n",
    "    ),\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "02b72635",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "API key present: True\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "DATA_GOV_IN_API_KEY is not set. Get a key on data.gov.in and set it in env.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[45]\u001b[39m\u001b[32m, line 16\u001b[39m\n\u001b[32m      4\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mAPI key present:\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28mbool\u001b[39m(os.getenv(\u001b[33m\"\u001b[39m\u001b[33mDATA_GOV_IN_API_KEY\u001b[39m\u001b[33m\"\u001b[39m)))\n\u001b[32m      6\u001b[39m demo_args = {\n\u001b[32m      7\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mstate\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33mKarnataka\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m      8\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mdistrict\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33mBelagavi\u001b[39m\u001b[33m\"\u001b[39m,     \u001b[38;5;66;03m# try also: \"Belgaum\"\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     13\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mmax_rows\u001b[39m\u001b[33m\"\u001b[39m: \u001b[32m100\u001b[39m,\n\u001b[32m     14\u001b[39m }\n\u001b[32m---> \u001b[39m\u001b[32m16\u001b[39m out = \u001b[43mprices_fetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdemo_args\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     17\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mSource:\u001b[39m\u001b[33m\"\u001b[39m, out[\u001b[33m\"\u001b[39m\u001b[33msource_stamp\u001b[39m\u001b[33m\"\u001b[39m])\n\u001b[32m     18\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mRows:\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28mlen\u001b[39m(out[\u001b[33m\"\u001b[39m\u001b[33mdata\u001b[39m\u001b[33m\"\u001b[39m]))\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[40]\u001b[39m\u001b[32m, line 26\u001b[39m, in \u001b[36mprices_fetch\u001b[39m\u001b[34m(args)\u001b[39m\n\u001b[32m     17\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m     18\u001b[39m \u001b[33;03mInputs: state, district, commodity, [market], [variety], [start_date], [end_date], [max_rows]\u001b[39;00m\n\u001b[32m     19\u001b[39m \u001b[33;03mReturns:\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     23\u001b[39m \u001b[33;03m  }\u001b[39;00m\n\u001b[32m     24\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m     25\u001b[39m a = MandiArgs(**args)\n\u001b[32m---> \u001b[39m\u001b[32m26\u001b[39m raw = \u001b[43magmarknet_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     27\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcommodity\u001b[49m\u001b[43m=\u001b[49m\u001b[43ma\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcommodity\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     28\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstate\u001b[49m\u001b[43m=\u001b[49m\u001b[43ma\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     29\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmarket\u001b[49m\u001b[43m=\u001b[49m\u001b[43ma\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmarket\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     30\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdistrict\u001b[49m\u001b[43m=\u001b[49m\u001b[43ma\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdistrict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     31\u001b[39m \u001b[43m    \u001b[49m\u001b[43mvariety\u001b[49m\u001b[43m=\u001b[49m\u001b[43ma\u001b[49m\u001b[43m.\u001b[49m\u001b[43mvariety\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     32\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstart_date\u001b[49m\u001b[43m=\u001b[49m\u001b[43ma\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstart_date\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     33\u001b[39m \u001b[43m    \u001b[49m\u001b[43mend_date\u001b[49m\u001b[43m=\u001b[49m\u001b[43ma\u001b[49m\u001b[43m.\u001b[49m\u001b[43mend_date\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     34\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmax_rows\u001b[49m\u001b[43m=\u001b[49m\u001b[43ma\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmax_rows\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     35\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     36\u001b[39m data = [_map_row_to_schema(r, raw[\u001b[33m\"\u001b[39m\u001b[33msource_url\u001b[39m\u001b[33m\"\u001b[39m]) \u001b[38;5;28;01mfor\u001b[39;00m r \u001b[38;5;129;01min\u001b[39;00m raw[\u001b[33m\"\u001b[39m\u001b[33mrecords\u001b[39m\u001b[33m\"\u001b[39m]]\n\u001b[32m     37\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m {\u001b[33m\"\u001b[39m\u001b[33mdata\u001b[39m\u001b[33m\"\u001b[39m: data, \u001b[33m\"\u001b[39m\u001b[33msource_stamp\u001b[39m\u001b[33m\"\u001b[39m: raw[\u001b[33m\"\u001b[39m\u001b[33msource_url\u001b[39m\u001b[33m\"\u001b[39m]}\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[38]\u001b[39m\u001b[32m, line 56\u001b[39m, in \u001b[36magmarknet_request\u001b[39m\u001b[34m(commodity, state, market, district, variety, start_date, end_date, max_rows)\u001b[39m\n\u001b[32m     53\u001b[39m url = \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mOGD_BASE\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mOGD_RESOURCE_ID\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m     55\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m56\u001b[39m     payload = \u001b[43m_ogd_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbase_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     57\u001b[39m     batch = payload.get(\u001b[33m\"\u001b[39m\u001b[33mrecords\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m payload.get(\u001b[33m\"\u001b[39m\u001b[33mdata\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m []\n\u001b[32m     58\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m batch:\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[37]\u001b[39m\u001b[32m, line 3\u001b[39m, in \u001b[36m_ogd_call\u001b[39m\u001b[34m(params)\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_ogd_call\u001b[39m(params: Dict[\u001b[38;5;28mstr\u001b[39m, Any]) -> Dict[\u001b[38;5;28mstr\u001b[39m, Any]:\n\u001b[32m      2\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m OGD_API_KEY:\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mDATA_GOV_IN_API_KEY is not set. Get a key on data.gov.in and set it in env.\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      4\u001b[39m     url = \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mOGD_BASE\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mOGD_RESOURCE_ID\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m      5\u001b[39m     resp = requests.get(url, params=params, timeout=\u001b[32m30\u001b[39m)\n",
      "\u001b[31mRuntimeError\u001b[39m: DATA_GOV_IN_API_KEY is not set. Get a key on data.gov.in and set it in env."
     ]
    }
   ],
   "source": [
    "# Set your key for this notebook session (or export in your shell)\n",
    "# os.environ[\"DATA_GOV_IN_API_KEY\"] = \"YOUR_KEY_HERE\"\n",
    "\n",
    "print(\"API key present:\", bool(os.getenv(\"DATA_GOV_IN_API_KEY\")))\n",
    "\n",
    "demo_args = {\n",
    "    \"state\": \"Karnataka\",\n",
    "    \"district\": \"Belagavi\",     # try also: \"Belgaum\"\n",
    "    \"commodity\": \"Tomato\",\n",
    "    # widen window if you see 0 rows\n",
    "    \"start_date\": None,\n",
    "    \"end_date\": None,\n",
    "    \"max_rows\": 100,\n",
    "}\n",
    "\n",
    "out = prices_fetch(demo_args)\n",
    "print(\"Source:\", out[\"source_stamp\"])\n",
    "print(\"Rows:\", len(out[\"data\"]))\n",
    "for i, r in enumerate(out[\"data\"][:5], 1):\n",
    "    print(f\"{i}. {r['arrival_date']} | {r['district']} > {r['market']} | {r['commodity']} ({r.get('variety')}) \"\n",
    "          f\"modal={r['modal_price_rs_per_qtl']} min={r['min_price_rs_per_qtl']} max={r['max_price_rs_per_qtl']}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64958f4f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2fd2d4d5",
   "metadata": {},
   "source": [
    "#SCRAPPING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "166ce204",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install --quiet requests beautifulsoup4 lxml pydantic langchain langchain-core python-dateutil pandas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "15c4b2e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import time\n",
    "from datetime import date\n",
    "from typing import Any, Dict, List, Optional\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from dateutil import parser as dateparser\n",
    "from pydantic import BaseModel, Field, validator\n",
    "\n",
    "try:\n",
    "    from langchain_core.tools import StructuredTool\n",
    "except ImportError:\n",
    "    from langchain.tools import StructuredTool\n",
    "\n",
    "AGMARKNET_SEARCH_URL = \"https://agmarknet.gov.in/SearchCmmMkt.aspx\"\n",
    "\n",
    "# polite scraping defaults\n",
    "DEFAULT_TIMEOUT = 30\n",
    "DEFAULT_SLEEP = 0.8  # seconds between GET and POST\n",
    "HEADERS = {\n",
    "    \"User-Agent\": \"Mozilla/5.0 (compatible; FasalSetuScraper/1.0; +https://example.com)\",\n",
    "    \"Accept-Language\": \"en-US,en;q=0.9\",\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "53858522",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _norm(x: Optional[str]) -> Optional[str]:\n",
    "    if x is None:\n",
    "        return None\n",
    "    s = str(x).strip()\n",
    "    return s if s else None\n",
    "\n",
    "def _to_float(x):\n",
    "    try:\n",
    "        return float(str(x).strip().replace(\",\", \"\"))\n",
    "    except Exception:\n",
    "        return None\n",
    "\n",
    "def _canon(val: Optional[str]) -> Optional[str]:\n",
    "    return _norm(val)\n",
    "\n",
    "def _in_date_range(d: Optional[str], start: Optional[str], end: Optional[str]) -> bool:\n",
    "    if not d:\n",
    "        return False\n",
    "    dd = dateparser.parse(d).date()\n",
    "    if start and dd < dateparser.parse(start).date():\n",
    "        return False\n",
    "    if end and dd > dateparser.parse(end).date():\n",
    "        return False\n",
    "    return True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "2e0254de",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _extract_hidden_fields(soup: BeautifulSoup) -> Dict[str, str]:\n",
    "    fields = {}\n",
    "    for name in [\"__VIEWSTATE\", \"__VIEWSTATEGENERATOR\", \"__EVENTVALIDATION\", \"__VIEWSTATEENCRYPTED\"]:\n",
    "        el = soup.find(\"input\", {\"name\": name})\n",
    "        if el and el.has_attr(\"value\"):\n",
    "            fields[name] = el[\"value\"]\n",
    "    # ASP.NET needs these even if empty\n",
    "    fields[\"__EVENTTARGET\"] = \"\"\n",
    "    fields[\"__EVENTARGUMENT\"] = \"\"\n",
    "    return fields\n",
    "\n",
    "def _find_field_name(soup: BeautifulSoup, label_text_candidates: List[str], fallback_regex: str) -> Optional[str]:\n",
    "    \"\"\"\n",
    "    Try to locate the 'name' attribute of a <select>/<input> whose <label> or nearby text\n",
    "    matches any of label_text_candidates. Otherwise fallback to regex on name/id.\n",
    "    \"\"\"\n",
    "    # 1) Try labels\n",
    "    for lab in soup.find_all([\"label\", \"span\"]):\n",
    "        text = (lab.get_text() or \"\").strip().lower()\n",
    "        if any(k in text for k in label_text_candidates):\n",
    "            # look for a nearby select/input\n",
    "            nxt = lab.find_next([\"select\", \"input\"])\n",
    "            if nxt and nxt.has_attr(\"name\"):\n",
    "                return nxt[\"name\"]\n",
    "\n",
    "    # 2) Regex fallback on name/id\n",
    "    pat = re.compile(fallback_regex, re.I)\n",
    "    for sel in soup.find_all([\"select\", \"input\"]):\n",
    "        nm = sel.get(\"name\") or sel.get(\"id\") or \"\"\n",
    "        if pat.search(nm):\n",
    "            return sel.get(\"name\") or sel.get(\"id\")\n",
    "\n",
    "    return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "7fd3e8ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "EXPECTED_HEADERS = {\n",
    "    \"state\": [\"state\"],\n",
    "    \"district\": [\"district\"],\n",
    "    \"market\": [\"market\", \"mkt\"],\n",
    "    \"arrival_date\": [\"date\", \"arrival date\"],\n",
    "    \"commodity\": [\"commodity\"],\n",
    "    \"variety\": [\"variety\"],\n",
    "    \"min_price\": [\"min price\", \"min\"],\n",
    "    \"max_price\": [\"max price\", \"max\"],\n",
    "    \"modal_price\": [\"modal price\", \"modal\"],\n",
    "    \"arrival\": [\"arrival\", \"arrivals\", \"qty\", \"quantity\"],\n",
    "}\n",
    "\n",
    "def _header_match(h: str, keys: List[str]) -> bool:\n",
    "    ht = (h or \"\").strip().lower()\n",
    "    return any(k in ht for k in keys)\n",
    "\n",
    "def _find_results_table(soup: BeautifulSoup):\n",
    "    # heuristic: choose the table whose header row contains at least 5 of the expected columns\n",
    "    best = None\n",
    "    best_score = -1\n",
    "    for tbl in soup.find_all(\"table\"):\n",
    "        headers = [th.get_text(strip=True) for th in tbl.find_all(\"th\")]\n",
    "        if not headers:\n",
    "            # try first row <tr><td> as header-like\n",
    "            first_tr = tbl.find(\"tr\")\n",
    "            if not first_tr:\n",
    "                continue\n",
    "            headers = [td.get_text(strip=True) for td in first_tr.find_all([\"td\", \"th\"])]\n",
    "        score = 0\n",
    "        for key, keys in EXPECTED_HEADERS.items():\n",
    "            if any(_header_match(h, keys) for h in headers):\n",
    "                score += 1\n",
    "        if score > best_score:\n",
    "            best_score = score\n",
    "            best = (tbl, headers)\n",
    "    return best  # (table, headers)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "b8cdddd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _map_to_schema(row: Dict[str, Any], source_url: str) -> Dict[str, Any]:\n",
    "    return {\n",
    "        \"state\": _canon(row.get(\"state\")),\n",
    "        \"district\": _canon(row.get(\"district\")),\n",
    "        \"market\": _canon(row.get(\"market\")),\n",
    "        \"arrival_date\": _canon(row.get(\"arrival_date\")),\n",
    "        \"commodity\": _canon(row.get(\"commodity\")),\n",
    "        \"variety\": _canon(row.get(\"variety\")),\n",
    "        \"min_price_rs_per_qtl\": _to_float(row.get(\"min_price\")),\n",
    "        \"max_price_rs_per_qtl\": _to_float(row.get(\"max_price\")),\n",
    "        \"modal_price_rs_per_qtl\": _to_float(row.get(\"modal_price\")),\n",
    "        \"arrival_qty\": _to_float(row.get(\"arrival\")),\n",
    "        \"source_url\": source_url,\n",
    "        \"last_checked\": date.today().isoformat(),\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "e9fdb489",
   "metadata": {},
   "outputs": [],
   "source": [
    "def agmarknet_scrape(\n",
    "    commodity: str,\n",
    "    state: str,\n",
    "    district: Optional[str] = None,\n",
    "    market: Optional[str] = None,\n",
    "    start_date: Optional[str] = None,  # YYYY-MM-DD\n",
    "    end_date: Optional[str] = None,    # YYYY-MM-DD\n",
    ") -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Scrape AGMARKNET SearchCmmMkt.aspx like the GitHub repo approach (no data.gov.in API).\n",
    "    Returns: { \"records\": [raw_rows], \"source_url\": <page URL> }\n",
    "    \"\"\"\n",
    "    session = requests.Session()\n",
    "    session.headers.update(HEADERS)\n",
    "\n",
    "    # Step 1: GET the search page to collect WebForms tokens and control names\n",
    "    r = session.get(AGMARKNET_SEARCH_URL, timeout=DEFAULT_TIMEOUT)\n",
    "    r.raise_for_status()\n",
    "    soup = BeautifulSoup(r.text, \"lxml\")\n",
    "\n",
    "    hidden = _extract_hidden_fields(soup)\n",
    "\n",
    "    # Try to discover likely control names for dropdowns/inputs\n",
    "    name_state = _find_field_name(soup, [\"state\"], r\"state|ddlstate\")\n",
    "    name_district = _find_field_name(soup, [\"district\"], r\"district|ddldistrict\")\n",
    "    name_market = _find_field_name(soup, [\"market\"], r\"market|ddlmarket|apmc\")\n",
    "    name_commodity = _find_field_name(soup, [\"commodity\"], r\"commodity|ddlcommodity\")\n",
    "    name_from = _find_field_name(soup, [\"from\", \"from date\", \"start\"], r\"from|start|fromdate\")\n",
    "    name_to = _find_field_name(soup, [\"to\", \"to date\", \"end\"], r\"to|end|todate\")\n",
    "\n",
    "    # A common submit button name/id on this page is often like 'btnGo' / 'btnSearch'\n",
    "    # We'll try to find any submit button.\n",
    "    btn = soup.find(\"input\", {\"type\": \"submit\"}) or soup.find(\"button\", {\"type\": \"submit\"})\n",
    "    submit_name = (btn.get(\"name\") if btn and btn.has_attr(\"name\") else \"btnGo\")\n",
    "\n",
    "    # Build payload (ASP.NET requires ALL visible form inputs; at minimum hidden + your fields)\n",
    "    payload = dict(hidden)  # copies __VIEWSTATE, etc.\n",
    "    if name_state:\n",
    "        payload[name_state] = state\n",
    "    if name_district and district:\n",
    "        payload[name_district] = district\n",
    "    if name_market and market:\n",
    "        payload[name_market] = market\n",
    "    if name_commodity:\n",
    "        payload[name_commodity] = commodity\n",
    "    if name_from and start_date:\n",
    "        payload[name_from] = start_date\n",
    "    if name_to and end_date:\n",
    "        payload[name_to] = end_date\n",
    "\n",
    "    # ASP.NET WebForms usually needs a submit name in payload\n",
    "    payload[submit_name] = \"Search\"\n",
    "\n",
    "    # Small delay to be polite\n",
    "    time.sleep(DEFAULT_SLEEP)\n",
    "\n",
    "    # Step 2: POST the form\n",
    "    r2 = session.post(AGMARKNET_SEARCH_URL, data=payload, timeout=DEFAULT_TIMEOUT, headers=HEADERS)\n",
    "    r2.raise_for_status()\n",
    "    soup2 = BeautifulSoup(r2.text, \"lxml\")\n",
    "\n",
    "    # Step 3: locate the results table\n",
    "    tbl_headers = _find_results_table(soup2)\n",
    "    if not tbl_headers:\n",
    "        # Sometimes results are rendered in update panels — try another pass: look for any table with 'Commodity'\n",
    "        candidates = soup2.find_all(\"table\")\n",
    "        if not candidates:\n",
    "            raise RuntimeError(\"Could not locate any results table on AGMARKNET page.\")\n",
    "        # fallback: pick the first table as a last resort\n",
    "        tbl = candidates[0]\n",
    "        headers = [th.get_text(strip=True) for th in tbl.find_all(\"th\")]\n",
    "    else:\n",
    "        tbl, headers = tbl_headers\n",
    "\n",
    "    # Normalize header names and build column index map\n",
    "    head_texts = [h.strip() for h in headers] if headers else []\n",
    "    if not head_texts:\n",
    "        # try first row as header\n",
    "        first_tr = tbl.find(\"tr\")\n",
    "        head_texts = [td.get_text(strip=True) for td in first_tr.find_all([\"td\",\"th\"])] if first_tr else []\n",
    "\n",
    "    col_map = {}\n",
    "    for idx, h in enumerate(head_texts):\n",
    "        ht = h.lower()\n",
    "        if any(k in ht for k in EXPECTED_HEADERS[\"state\"]): col_map[\"state\"] = idx\n",
    "        if any(k in ht for k in EXPECTED_HEADERS[\"district\"]): col_map[\"district\"] = idx\n",
    "        if any(k in ht for k in EXPECTED_HEADERS[\"market\"]): col_map[\"market\"] = idx\n",
    "        if any(k in ht for k in EXPECTED_HEADERS[\"arrival_date\"]): col_map[\"arrival_date\"] = idx\n",
    "        if any(k in ht for k in EXPECTED_HEADERS[\"commodity\"]): col_map[\"commodity\"] = idx\n",
    "        if any(k in ht for k in EXPECTED_HEADERS[\"variety\"]): col_map[\"variety\"] = idx\n",
    "        if any(k in ht for k in EXPECTED_HEADERS[\"min_price\"]): col_map[\"min_price\"] = idx\n",
    "        if any(k in ht for k in EXPECTED_HEADERS[\"max_price\"]): col_map[\"max_price\"] = idx\n",
    "        if any(k in ht for k in EXPECTED_HEADERS[\"modal_price\"]): col_map[\"modal_price\"] = idx\n",
    "        if any(k in ht for k in EXPECTED_HEADERS[\"arrival\"]): col_map[\"arrival\"] = idx\n",
    "\n",
    "    # Step 4: iterate data rows\n",
    "    rows = []\n",
    "    for tr in tbl.find_all(\"tr\"):\n",
    "        tds = tr.find_all(\"td\")\n",
    "        if not tds or len(tds) < max(col_map.values(), default=0)+1:\n",
    "            continue\n",
    "        # Heuristic: skip header-like rows\n",
    "        if tds[0].find(\"th\"): \n",
    "            continue\n",
    "\n",
    "        def pick(key):\n",
    "            i = col_map.get(key, None)\n",
    "            return tds[i].get_text(strip=True) if i is not None else None\n",
    "\n",
    "        row = {\n",
    "            \"state\": pick(\"state\"),\n",
    "            \"district\": pick(\"district\"),\n",
    "            \"market\": pick(\"market\"),\n",
    "            \"arrival_date\": pick(\"arrival_date\"),\n",
    "            \"commodity\": pick(\"commodity\"),\n",
    "            \"variety\": pick(\"variety\"),\n",
    "            \"min_price\": pick(\"min_price\"),\n",
    "            \"max_price\": pick(\"max_price\"),\n",
    "            \"modal_price\": pick(\"modal_price\"),\n",
    "            \"arrival\": pick(\"arrival\"),\n",
    "        }\n",
    "\n",
    "        # If a date window was passed, filter here (site may ignore date fields if selections are partial)\n",
    "        if (start_date or end_date) and not _in_date_range(row.get(\"arrival_date\"), start_date, end_date):\n",
    "            continue\n",
    "\n",
    "        rows.append(row)\n",
    "\n",
    "    return {\"records\": rows, \"source_url\": AGMARKNET_SEARCH_URL}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "23a3bd1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Hp\\AppData\\Local\\Temp\\ipykernel_19496\\1067131509.py:10: PydanticDeprecatedSince20: Pydantic V1 style `@validator` validators are deprecated. You should migrate to Pydantic V2 style `@field_validator` validators, see the migration guide for more details. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.11/migration/\n",
      "  @validator(\"start_date\", \"end_date\")\n"
     ]
    }
   ],
   "source": [
    "class ScrapeArgs(BaseModel):\n",
    "    state: str\n",
    "    district: Optional[str] = None\n",
    "    commodity: str\n",
    "    market: Optional[str] = None\n",
    "    start_date: Optional[str] = None  # YYYY-MM-DD\n",
    "    end_date: Optional[str] = None\n",
    "    max_rows: int = 1000\n",
    "\n",
    "    @validator(\"start_date\", \"end_date\")\n",
    "    def _datefmt(cls, v):\n",
    "        if v is None:\n",
    "            return v\n",
    "        return dateparser.parse(v).date().isoformat()\n",
    "\n",
    "def prices_fetch_scrape(args: Dict[str, Any]) -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Scraping-based mandi lookup (AGMARKNET HTML), returns your schema + source_stamp.\n",
    "    \"\"\"\n",
    "    a = ScrapeArgs(**args)\n",
    "    raw = agmarknet_scrape(\n",
    "        commodity=a.commodity,\n",
    "        state=a.state,\n",
    "        district=a.district,\n",
    "        market=a.market,\n",
    "        start_date=a.start_date,\n",
    "        end_date=a.end_date,\n",
    "    )\n",
    "    # map & cap\n",
    "    mapped = [_map_to_schema(r, raw[\"source_url\"]) for r in raw[\"records\"]]\n",
    "    return {\"data\": mapped[: a.max_rows], \"source_stamp\": raw[\"source_url\"]}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "da245311",
   "metadata": {},
   "outputs": [],
   "source": [
    "MandiPricesScrapeTool = StructuredTool.from_function(\n",
    "    func=prices_fetch_scrape,\n",
    "    name=\"mandi_prices_scrape\",\n",
    "    description=(\n",
    "        \"Scrape AGMARKNET (SearchCmmMkt.aspx) for daily mandi prices — repo-style scraper. \"\n",
    "        \"Inputs: state, district, commodity, [market], [start_date], [end_date], [max_rows]. \"\n",
    "        \"Returns {data: [...], source_stamp: '...'} in Fasal-Setu schema.\"\n",
    "    ),\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "bb55ba4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source: https://agmarknet.gov.in/SearchCmmMkt.aspx\n",
      "Rows: 4\n",
      "1. None | None > None > None | None (None) modal=None min=None max=None\n",
      "2. None | None > None > None | None (None) modal=None min=None max=None\n",
      "3. None | None > None > None | None (None) modal=None min=None max=None\n",
      "4. None | None > None > None | None (None) modal=None min=None max=None\n"
     ]
    }
   ],
   "source": [
    "demo_args = {\n",
    "    \"state\": \"Bihar\",\n",
    "    \"district\": \"\",       # try alternate spellings if needed (\"Belgaum\")\n",
    "    \"commodity\": \"Rice\",\n",
    "    # \"market\": \"Belagavi APMC\",  # optional\n",
    "    # \"start_date\": \"2025-08-01\",\n",
    "    # \"end_date\": \"2025-08-15\",\n",
    "    \"max_rows\": 50,\n",
    "}\n",
    "\n",
    "out = prices_fetch_scrape(demo_args)\n",
    "print(\"Source:\", out[\"source_stamp\"])\n",
    "print(\"Rows:\", len(out[\"data\"]))\n",
    "for i, r in enumerate(out[\"data\"][:5], 1):\n",
    "    print(f\"{i}. {r['arrival_date']} | {r['state']} > {r['district']} > {r['market']} \"\n",
    "          f\"| {r['commodity']} ({r.get('variety')}) \"\n",
    "          f\"modal={r['modal_price_rs_per_qtl']} min={r['min_price_rs_per_qtl']} max={r['max_price_rs_per_qtl']}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d455f51e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
